{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43cbdeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ac1a278f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 32, 32, 4), (500, 3, 4), (500, 3), (500, 3))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cairo\n",
    "import random\n",
    "\n",
    "\n",
    "t=0\n",
    "num_imgs = 500\n",
    "\n",
    "img_size = 32\n",
    "min_object_size = 4\n",
    "max_object_size = 5\n",
    "num_objects = 3\n",
    "\n",
    "bboxes = np.zeros((num_imgs, num_objects, 4))\n",
    "imgs = np.zeros((num_imgs, img_size, img_size, 4), dtype=np.uint8)  # format: BGRA\n",
    "shapes = np.zeros((num_imgs, num_objects), dtype=int)\n",
    "num_shapes = 3\n",
    "#shape_labels = ['rectangle', 'circle', 'triangle']\n",
    "colors = np.zeros((num_imgs, num_objects), dtype=int)\n",
    "num_colors = 3\n",
    "color_labels = ['r', 'g', 'b']\n",
    "\n",
    "for i_img in range(num_imgs):\n",
    "    surface = cairo.ImageSurface.create_for_data(imgs[i_img], cairo.FORMAT_ARGB32, img_size, img_size)\n",
    "    cr = cairo.Context(surface)\n",
    "\n",
    "    # Fill background white.\n",
    "    cr.set_source_rgb(255, 128, 0)\n",
    "    cr.paint()\n",
    "    \n",
    "    # TODO: Try no overlap here.\n",
    "    # Draw random shapes.\n",
    "   \n",
    "    # -------------------------------------------------------------------------------------------------\n",
    "\n",
    "    def fst1():\n",
    "        w, h = np.random.randint(min_object_size, max_object_size, size=2)\n",
    "                #x = np.random.randint(0, img_size - w)\n",
    "        x = 4 \n",
    "                #y = np.random.randint(0, img_size - h)\n",
    "        y = 4\n",
    "        bboxes[i_img, i_object] = [x, y, w, h]\n",
    "        cr.rectangle(x, y, w, h) \n",
    "                \n",
    "    def scnd1():\n",
    "        r = 1 * np.random.randint(min_object_size, max_object_size)\n",
    "        # x = np.random.randint(r, img_size - r)\n",
    "        x = 4\n",
    "        # y = np.random.randint(r, img_size - r)\n",
    "        y = 4\n",
    "        bboxes[i_img, i_object] = [x - r, y - r, 2 * r, 2 * r]\n",
    "        cr.arc(x, y, r, 0, 2*np.pi)                 \n",
    "        \n",
    "    def thrd1():\n",
    "        w, h = np.random.randint(3,4 , size=2)\n",
    "                #x = np.random.randint(0, img_size - w)\n",
    "        x = 1 \n",
    "                #y = np.random.randint(0, img_size - h)\n",
    "        y = 1\n",
    "        bboxes[i_img, i_object] = [x, y, w, h]\n",
    "        cr.rectangle(x, y, w, h)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    random.choice([fst1,scnd1,thrd1])()\n",
    "\n",
    "    \n",
    "    \n",
    "#--------------------------------------------------------------------------------    \n",
    "        \n",
    "    def thid():\n",
    "        r = 0.7 * np.random.randint(min_object_size, max_object_size)\n",
    "        #    x = np.random.randint(r, img_size - r)\n",
    "        x = 4\n",
    "        #    y = np.random.randint(r, img_size - r)\n",
    "        y = img_size - 12\n",
    "        bboxes[i_img, i_object] = [x - r, y - r, 2 * r, 2 * r]\n",
    "        cr.arc(x, y, r, 0, 2*np.pi)    \n",
    "        \n",
    "    random.choice([thid])()    \n",
    "        \n",
    "    \n",
    "            \n",
    "         # circle   \n",
    "    \n",
    "      #  elif shape == 2:  # triangle\n",
    "      #      w, h = np.random.randint(min_object_size, max_object_size, size=2)\n",
    "      #      x = np.random.randint(0, img_size - w)\n",
    "      #      y = np.random.randint(0, img_size - h)\n",
    "      #      bboxes[i_img, i_object] = [x, y, w, h]\n",
    "      #      cr.move_to(x, y)\n",
    "       #     cr.line_to(x+w, y)\n",
    "      #      cr.line_to(x+w, y+h)\n",
    "      #      cr.line_to(x, y)\n",
    "       #     cr.close_path()\n",
    "        \n",
    "        # TODO: Introduce some variation to the colors by adding a small random offset to the rgb values.\n",
    "    color = np.random.randint(num_colors)\n",
    "    colors[i_img, i_object] = color\n",
    "    max_offset = 0\n",
    "    r_offset, g_offset, b_offset = max_offset * 2. * (np.random.rand(3) - 0.1)\n",
    "    if color == 0:\n",
    "        cr.set_source_rgb(1-max_offset+r_offset, 0+g_offset, 0+b_offset)\n",
    "    elif color == 1:\n",
    "        cr.set_source_rgb(0+r_offset, 1-max_offset+g_offset, 0+b_offset)\n",
    "    elif color == 2:\n",
    "        cr.set_source_rgb(0+r_offset, 0-max_offset+g_offset, 1+b_offset)\n",
    "    cr.set_source_rgb(0,0,0)\n",
    "    cr.fill()\n",
    "        \n",
    "#imgs = imgs[..., 2::-1]  # is BGRA, convert to RGB\n",
    "\n",
    "# surface.write_to_png('imgs/{}.png'.format(i_img))\n",
    "imgs.shape, bboxes.shape, shapes.shape, colors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1a837472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 5\n",
    "plt.imshow(imgs[i], interpolation='none', origin='lower', extent=[0, img_size, 0, img_size])\n",
    "for bbox, shape, in zip(bboxes[i], shapes[i]):\n",
    "    plt.gca().add_patch(matplotlib.patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], ec='k', fc='none'))\n",
    "    plt.annotate(shape_labels[shape],(bbox[0], bbox[1] + bbox[3] + 0.1), clip_on=False)\n",
    "# surface.write_to_png(\"circle.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "12e26fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 32, 32, 3), (500, 3, 4), (500, 3), (500, 3))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cairo\n",
    "import random\n",
    "\n",
    "\n",
    "t=0\n",
    "num_imgs = 500\n",
    "\n",
    "img_size = 32\n",
    "min_object_size = 4\n",
    "max_object_size = 5\n",
    "num_objects = 3\n",
    "\n",
    "bboxes = np.zeros((num_imgs, num_objects, 4))\n",
    "imgs = np.zeros((num_imgs, img_size, img_size, 4), dtype=np.uint8)  # format: BGRA\n",
    "shapes = np.zeros((num_imgs, num_objects), dtype=int)\n",
    "num_shapes = 3\n",
    "shape_labels = ['rectangle', 'circle', 'triangle']\n",
    "colors = np.zeros((num_imgs, num_objects), dtype=int)\n",
    "num_colors = 3\n",
    "color_labels = ['r', 'g', 'b']\n",
    "\n",
    "for i_img in range(num_imgs):\n",
    "    surface = cairo.ImageSurface.create_for_data(imgs[i_img], cairo.FORMAT_ARGB32, img_size, img_size)\n",
    "    cr = cairo.Context(surface)\n",
    "\n",
    "    # Fill background white.\n",
    "    cr.set_source_rgb(1, 1, 1)\n",
    "    cr.paint()\n",
    "    \n",
    "    # TODO: Try no overlap here.\n",
    "    # Draw random shapes.\n",
    "    for i_object in range(num_objects):\n",
    "        shape = np.random.randint(num_shapes)\n",
    "        shapes[i_img, i_object] = shape\n",
    "        if shape == 0:# rectangle\n",
    "            def fst():\n",
    "                w, h = np.random.randint(min_object_size, max_object_size, size=2)\n",
    "                #x = np.random.randint(0, img_size - w)\n",
    "                x = 0 \n",
    "                #y = np.random.randint(0, img_size - h)\n",
    "                y = img_size -4\n",
    "                bboxes[i_img, i_object] = [x, y, w, h]\n",
    "                cr.rectangle(x, y, w, h) \n",
    "                \n",
    "            def scnd():\n",
    "                \n",
    "                r = 1 * np.random.randint(min_object_size, max_object_size)\n",
    "                # x = np.random.randint(r, img_size - r)\n",
    "                x = 4\n",
    "                # y = np.random.randint(r, img_size - r)\n",
    "                y = img_size - 4\n",
    "                bboxes[i_img, i_object] = [x - r, y - r, 2 * r, 2 * r]\n",
    "                cr.arc(x, y, r, 0, 2*np.pi)\n",
    "                \n",
    "                    \n",
    "                    \n",
    "            \n",
    "            random.choice([fst,scnd])()\n",
    "            \n",
    "            \n",
    "        elif shape == 1:  # circle   \n",
    "            r = 1 * np.random.randint(min_object_size, max_object_size)\n",
    "        #    x = np.random.randint(r, img_size - r)\n",
    "            x = 4\n",
    "        #    y = np.random.randint(r, img_size - r)\n",
    "            y = img_size - 12\n",
    "            bboxes[i_img, i_object] = [x - r, y - r, 2 * r, 2 * r]\n",
    "            cr.arc(x, y, r, 0, 2*np.pi)\n",
    "      #  elif shape == 2:  # triangle\n",
    "      #      w, h = np.random.randint(min_object_size, max_object_size, size=2)\n",
    "      #      x = np.random.randint(0, img_size - w)\n",
    "      #      y = np.random.randint(0, img_size - h)\n",
    "      #      bboxes[i_img, i_object] = [x, y, w, h]\n",
    "      #      cr.move_to(x, y)\n",
    "       #     cr.line_to(x+w, y)\n",
    "      #      cr.line_to(x+w, y+h)\n",
    "      #      cr.line_to(x, y)\n",
    "       #     cr.close_path()\n",
    "        \n",
    "        # TODO: Introduce some variation to the colors by adding a small random offset to the rgb values.\n",
    "        color = np.random.randint(num_colors)\n",
    "        colors[i_img, i_object] = color\n",
    "        max_offset = 0.3\n",
    "        r_offset, g_offset, b_offset = max_offset * 2. * (np.random.rand(3) - 0.5)\n",
    "        if color == 0:\n",
    "            cr.set_source_rgb(1-max_offset+r_offset, 0+g_offset, 0+b_offset)\n",
    "        elif color == 1:\n",
    "            cr.set_source_rgb(0+r_offset, 1-max_offset+g_offset, 0+b_offset)\n",
    "        elif color == 2:\n",
    "            cr.set_source_rgb(0+r_offset, 0-max_offset+g_offset, 1+b_offset)\n",
    "        cr.fill()\n",
    "        \n",
    "imgs = imgs[..., 2::-1]  # is BGRA, convert to RGB\n",
    "\n",
    "# surface.write_to_png('imgs/{}.png'.format(i_img))\n",
    "imgs.shape, bboxes.shape, shapes.shape, colors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b92dc148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 5\n",
    "plt.imshow(imgs[i], interpolation='none', origin='lower', extent=[0, img_size, 0, img_size])\n",
    "for bbox, shape, color in zip(bboxes[i], shapes[i], colors[i]):\n",
    "    plt.gca().add_patch(matplotlib.patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], ec='k', fc='none'))\n",
    "    plt.annotate(shape_labels[shape], (bbox[0], bbox[1] + bbox[3] + 0.1), color=color_labels[color], clip_on=False)\n",
    "# surface.write_to_png(\"circle.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc5606",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (imgs - 128.) / 255.\n",
    "X.shape, np.mean(X), np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf462112",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colors_onehot = np.zeros((num_imgs, num_objects, num_colors))\n",
    "for i_img in range(num_imgs):\n",
    "    for i_object in range(num_objects):\n",
    "        colors_onehot[i_img, i_object, colors[i_img, i_object]] = 1\n",
    "\n",
    "shapes_onehot = np.zeros((num_imgs, num_objects, num_shapes))\n",
    "for i_img in range(num_imgs):\n",
    "    for i_object in range(num_objects):\n",
    "        shapes_onehot[i_img, i_object, shapes[i_img, i_object]] = 1\n",
    "        \n",
    "y = np.concatenate([bboxes / img_size, shapes_onehot, colors_onehot], axis=-1).reshape(num_imgs, -1)\n",
    "y.shape, np.all(np.argmax(colors_onehot, axis=-1) == colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc856a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = int(0.8 * num_imgs)\n",
    "train_X = X[:i]\n",
    "test_X = X[i:]\n",
    "train_y = y[:i]\n",
    "test_y = y[i:]\n",
    "test_imgs = imgs[i:]\n",
    "test_bboxes = bboxes[i:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae74ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Activation,Conv2D,MaxPooling2D,Flatten\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9236db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28866f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.add(layers.Conv2D(32, (6, 6), activation='relu', input_shape=X.shape[1:]))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8642dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eeada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(layers.Dense(256, activation='softmax'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(layers.Dense(y.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65934fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adadelta',\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ddc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_X, train_y, validation_data=(test_X, test_y), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "\n",
    "# Activate GPU for this, otherwise the convnet will take forever to train with Theano.\n",
    "\n",
    "# TODO: Make one run with very deep network (~10 layers).\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "\n",
    "# TODO: Maybe remove pooling bc it takes away the spatial information.\n",
    "\n",
    "model = Sequential([\n",
    "        Convolution2D(32, 6, 6, input_shape=X.shape[1:], data_format=\"channels_last\", activation='relu'), \n",
    "  #      MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Convolution2D(64, filter_size, filter_size, data_format=\"channels_last\", activation='relu'), \n",
    "      #  MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Convolution2D(128, filter_size, filter_size, data_format=\"channels_last\", activation='relu'), \n",
    "#          MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Convolution2D(128, filter_size, filter_size, data_format=\"channels_last\", activation='relu'), \n",
    " #       MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Flatten(), \n",
    "        Dropout(0.4), \n",
    "        Dense(256, activation='relu'), \n",
    "        Dropout(0.4), \n",
    "        Dense(y.shape[-1])\n",
    "    ])\n",
    "\n",
    "model.compile('adadelta', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce703d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(32,32,3)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4556c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f9067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip bboxes during training.\n",
    "# Note: The validation loss is always quite big here because we don't flip the bounding boxes for the validation data. \n",
    "def IOU(bbox1, bbox2):\n",
    "    '''Calculate overlap between two bounding boxes [x, y, w, h] as the area of intersection over the area of unity'''\n",
    "    x1, y1, w1, h1 = bbox1[0], bbox1[1], bbox1[2], bbox1[3]  # TODO: Check if its more performant if tensor elements are accessed directly below.\n",
    "    x2, y2, w2, h2 = bbox2[0], bbox2[1], bbox2[2], bbox2[3]\n",
    "\n",
    "    w_I = min(x1 + w1, x2 + w2) - max(x1, x2)\n",
    "    h_I = min(y1 + h1, y2 + h2) - max(y1, y2)\n",
    "    if w_I <= 0 or h_I <= 0:  # no overlap\n",
    "        return 0\n",
    "    I = w_I * h_I\n",
    "\n",
    "    U = w1 * h1 + w2 * h2 - I\n",
    "\n",
    "    return I / U\n",
    "\n",
    "def dist(bbox1, bbox2):\n",
    "    return np.sqrt(np.sum(np.square(bbox1[:2] - bbox2[:2])))\n",
    "\n",
    "num_epochs_flipping = 50\n",
    "num_epochs_no_flipping = 0  # has no significant effect\n",
    "\n",
    "flipped_train_y = np.array(train_y)\n",
    "flipped = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "ious_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "dists_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "mses_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "acc_shapes_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "acc_colors_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "\n",
    "flipped_test_y = np.array(test_y)\n",
    "flipped_test = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "ious_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "dists_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "mses_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "acc_shapes_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "acc_colors_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "\n",
    "# TODO: Calculate ious directly for all samples (using slices of the array pred_y for x, y, w, h).\n",
    "for epoch in range(num_epochs_flipping):\n",
    "    print('Epoch', epoch)\n",
    "    model.fit(train_X, flipped_train_y, validation_data=(test_X, test_y), verbose=2)\n",
    "    pred_y = model.predict(train_X)\n",
    "\n",
    "    for sample, (pred, exp) in enumerate(zip(pred_y, flipped_train_y)):\n",
    "        \n",
    "        # TODO: Make this simpler.\n",
    "        pred = pred.reshape(num_objects, -1)\n",
    "        exp = exp.reshape(num_objects, -1)\n",
    "        \n",
    "        pred_bboxes = pred[:, :4]\n",
    "        exp_bboxes = exp[:, :4]\n",
    "        \n",
    "        ious = np.zeros((num_objects, num_objects))\n",
    "        dists = np.zeros((num_objects, num_objects))\n",
    "        mses = np.zeros((num_objects, num_objects))\n",
    "        for i, exp_bbox in enumerate(exp_bboxes):\n",
    "            for j, pred_bbox in enumerate(pred_bboxes):\n",
    "                ious[i, j] = IOU(exp_bbox, pred_bbox)\n",
    "                dists[i, j] = dist(exp_bbox, pred_bbox)\n",
    "                mses[i, j] = np.mean(np.square(exp_bbox - pred_bbox))\n",
    "                \n",
    "        new_order = np.zeros(num_objects, dtype=int)\n",
    "        \n",
    "        for i in range(num_objects):\n",
    "            # Find pred and exp bbox with maximum iou and assign them to each other (i.e. switch the positions of the exp bboxes in y).\n",
    "            ind_exp_bbox, ind_pred_bbox = np.unravel_index(ious.argmax(), ious.shape)\n",
    "            ious_epoch[sample, epoch] += ious[ind_exp_bbox, ind_pred_bbox]\n",
    "            dists_epoch[sample, epoch] += dists[ind_exp_bbox, ind_pred_bbox]\n",
    "            mses_epoch[sample, epoch] += mses[ind_exp_bbox, ind_pred_bbox]\n",
    "            ious[ind_exp_bbox] = -1  # set iou of assigned bboxes to -1, so they don't get assigned again\n",
    "            ious[:, ind_pred_bbox] = -1\n",
    "            new_order[ind_pred_bbox] = ind_exp_bbox\n",
    "        \n",
    "        flipped_train_y[sample] = exp[new_order].flatten()\n",
    "        \n",
    "        flipped[sample, epoch] = 1. - np.mean(new_order == np.arange(num_objects, dtype=int))#np.array_equal(new_order, np.arange(num_objects, dtype=int))  # TODO: Change this to reflect the number of flips.\n",
    "        ious_epoch[sample, epoch] /= num_objects\n",
    "        dists_epoch[sample, epoch] /= num_objects\n",
    "        mses_epoch[sample, epoch] /= num_objects\n",
    "        \n",
    "        acc_shapes_epoch[sample, epoch] = np.mean(np.argmax(pred[:, 4:4+num_shapes], axis=-1) == np.argmax(exp[:, 4:4+num_shapes], axis=-1))\n",
    "        acc_colors_epoch[sample, epoch] = np.mean(np.argmax(pred[:, 4+num_shapes:4+num_shapes+num_colors], axis=-1) == np.argmax(exp[:, 4+num_shapes:4+num_shapes+num_colors], axis=-1))\n",
    "\n",
    "    \n",
    "    # Calculate metrics on test data. \n",
    "    pred_test_y = model.predict(test_X)\n",
    "    # TODO: Make this simpler.\n",
    "    for sample, (pred, exp) in enumerate(zip(pred_test_y, flipped_test_y)):\n",
    "        \n",
    "        # TODO: Make this simpler.\n",
    "        pred = pred.reshape(num_objects, -1)\n",
    "        exp = exp.reshape(num_objects, -1)\n",
    "        \n",
    "        pred_bboxes = pred[:, :4]\n",
    "        exp_bboxes = exp[:, :4]\n",
    "        \n",
    "        ious = np.zeros((num_objects, num_objects))\n",
    "        dists = np.zeros((num_objects, num_objects))\n",
    "        mses = np.zeros((num_objects, num_objects))\n",
    "        for i, exp_bbox in enumerate(exp_bboxes):\n",
    "            for j, pred_bbox in enumerate(pred_bboxes):\n",
    "                ious[i, j] = IOU(exp_bbox, pred_bbox)\n",
    "                dists[i, j] = dist(exp_bbox, pred_bbox)\n",
    "                mses[i, j] = np.mean(np.square(exp_bbox - pred_bbox))\n",
    "                \n",
    "        new_order = np.zeros(num_objects, dtype=int)\n",
    "        \n",
    "        for i in range(num_objects):\n",
    "            # Find pred and exp bbox with maximum iou and assign them to each other (i.e. switch the positions of the exp bboxes in y).\n",
    "            ind_exp_bbox, ind_pred_bbox = np.unravel_index(mses.argmin(), mses.shape)\n",
    "            ious_test_epoch[sample, epoch] += ious[ind_exp_bbox, ind_pred_bbox]\n",
    "            dists_test_epoch[sample, epoch] += dists[ind_exp_bbox, ind_pred_bbox]\n",
    "            mses_test_epoch[sample, epoch] += mses[ind_exp_bbox, ind_pred_bbox]\n",
    "            mses[ind_exp_bbox] = 1000000#-1  # set iou of assigned bboxes to -1, so they don't get assigned again\n",
    "            mses[:, ind_pred_bbox] = 10000000#-1\n",
    "            new_order[ind_pred_bbox] = ind_exp_bbox\n",
    "        \n",
    "        flipped_test_y[sample] = exp[new_order].flatten()\n",
    "        \n",
    "        flipped_test[sample, epoch] = 1. - np.mean(new_order == np.arange(num_objects, dtype=int))#np.array_equal(new_order, np.arange(num_objects, dtype=int))  # TODO: Change this to reflect the number of flips.\n",
    "        ious_test_epoch[sample, epoch] /= num_objects\n",
    "        dists_test_epoch[sample, epoch] /= num_objects\n",
    "        mses_test_epoch[sample, epoch] /= num_objects\n",
    "        \n",
    "        acc_shapes_test_epoch[sample, epoch] = np.mean(np.argmax(pred[:, 4:4+num_shapes], axis=-1) == np.argmax(exp[:, 4:4+num_shapes], axis=-1))\n",
    "        acc_colors_test_epoch[sample, epoch] = np.mean(np.argmax(pred[:, 4+num_shapes:4+num_shapes+num_colors], axis=-1) == np.argmax(exp[:, 4+num_shapes:4+num_shapes+num_colors], axis=-1))\n",
    "       \n",
    "            \n",
    "    print('Flipped {} % of all elements'.format(np.mean(flipped[:, epoch]) * 100.))\n",
    "    print('Mean IOU: {}'.format(np.mean(ious_epoch[:, epoch])))\n",
    "    print('Mean dist: {}'.format(np.mean(dists_epoch[:, epoch])))\n",
    "    print('Mean mse: {}'.format(np.mean(mses_epoch[:, epoch])))\n",
    "    print('Accuracy shapes: {}'.format(np.mean(acc_shapes_epoch[:, epoch])))\n",
    "    print('Accuracy colors: {}'.format(np.mean(acc_colors_epoch[:, epoch])))\n",
    "    \n",
    "    print('--------------- TEST ----------------') \n",
    "    print('Flipped {} % of all elements'.format(np.mean(flipped_test[:, epoch]) * 100.))\n",
    "    print('Mean IOU: {}'.format(np.mean(ious_test_epoch[:, epoch])))\n",
    "    print('Mean dist: {}'.format(np.mean(dists_test_epoch[:, epoch])))\n",
    "    print('Mean mse: {}'.format(np.mean(mses_test_epoch[:, epoch])))\n",
    "    print('Accuracy shapes: {}'.format(np.mean(acc_shapes_test_epoch[:, epoch])))\n",
    "    print('Accuracy colors: {}'.format(np.mean(acc_colors_test_epoch[:, epoch])))\n",
    "    #print\n",
    "    \n",
    "# print '------------------------------------'\n",
    "# print 'Training now without flipping bboxes'\n",
    "# print '------------------------------------'\n",
    "    \n",
    "# for epoch in range(num_epochs_flipping, num_epochs_flipping + num_epochs_no_flipping):\n",
    "#     print 'Epoch', epoch\n",
    "#     model.fit(train_X, flipped_train_y, nb_epoch=1, validation_data=(test_X, test_y), verbose=2)\n",
    "#     pred_y = model.predict(train_X)\n",
    "\n",
    "#     # Calculate iou/dist, but don't flip.\n",
    "#     for sample, (pred_bboxes, exp_bboxes) in enumerate(zip(pred_y, flipped_train_y)):\n",
    "        \n",
    "#         pred_bboxes = pred_bboxes.reshape(num_objects, -1)\n",
    "#         exp_bboxes = exp_bboxes.reshape(num_objects, -1)        \n",
    "        \n",
    "#         for exp_bbox, pred_bbox in zip(exp_bboxes, pred_bboxes):\n",
    "#             ious_epoch[sample, epoch] += IOU(exp_bbox, pred_bbox)\n",
    "#             dists_epoch[sample, epoch] += dist(exp_bbox, pred_bbox)\n",
    "#             mses_epoch[sample, epoch] += np.mean(np.square(exp_bbox - pred_bbox))\n",
    "            \n",
    "#         ious_epoch[sample, epoch] /= num_objects\n",
    "#         dists_epoch[sample, epoch] /= num_objects \n",
    "#         mses_epoch[sample, epoch] /= num_objects \n",
    "            \n",
    "# #     print 'Flipped {} % of all elements'.format(np.mean(flipped[:, epoch]) * 100.)\n",
    "#     print 'Mean IOU: {}'.format(np.mean(ious_epoch[:, epoch]))\n",
    "#     print 'Mean dist: {}'.format(np.mean(dists_epoch[:, epoch]))\n",
    "#     print 'Mean mse: {}'.format(np.mean(mses_epoch[:, epoch]))\n",
    "#     print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aece14e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
