{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43cbdeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12e26fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 32, 32, 3), (500, 2, 4), (500, 2), (500, 2))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cairo\n",
    "num_imgs = 500\n",
    "\n",
    "img_size = 32\n",
    "min_object_size = 4\n",
    "max_object_size = 16\n",
    "num_objects = 2\n",
    "\n",
    "bboxes = np.zeros((num_imgs, num_objects, 4))\n",
    "imgs = np.zeros((num_imgs, img_size, img_size, 4), dtype=np.uint8)  # format: BGRA\n",
    "shapes = np.zeros((num_imgs, num_objects), dtype=int)\n",
    "num_shapes = 3\n",
    "shape_labels = ['rectangle', 'circle', 'triangle']\n",
    "colors = np.zeros((num_imgs, num_objects), dtype=int)\n",
    "num_colors = 3\n",
    "color_labels = ['r', 'g', 'b']\n",
    "\n",
    "for i_img in range(num_imgs):\n",
    "    surface = cairo.ImageSurface.create_for_data(imgs[i_img], cairo.FORMAT_ARGB32, img_size, img_size)\n",
    "    cr = cairo.Context(surface)\n",
    "\n",
    "    # Fill background white.\n",
    "    cr.set_source_rgb(1, 1, 1)\n",
    "    cr.paint()\n",
    "    \n",
    "    # TODO: Try no overlap here.\n",
    "    # Draw random shapes.\n",
    "    for i_object in range(num_objects):\n",
    "        shape = np.random.randint(num_shapes)\n",
    "        shapes[i_img, i_object] = shape\n",
    "        if shape == 0:  # rectangle\n",
    "            w, h = np.random.randint(min_object_size, max_object_size, size=2)\n",
    "            x = np.random.randint(0, img_size - w)\n",
    "            y = np.random.randint(0, img_size - h)\n",
    "            bboxes[i_img, i_object] = [x, y, w, h]\n",
    "            cr.rectangle(x, y, w, h)          \n",
    "        elif shape == 1:  # circle   \n",
    "            r = 1 * np.random.randint(min_object_size, max_object_size)\n",
    "            x = np.random.randint(r, img_size - r)\n",
    "            y = np.random.randint(r, img_size - r)\n",
    "            bboxes[i_img, i_object] = [x - r, y - r, 2 * r, 2 * r]\n",
    "            cr.arc(x, y, r, 0, 2*np.pi)\n",
    "        elif shape == 2:  # triangle\n",
    "            w, h = np.random.randint(min_object_size, max_object_size, size=2)\n",
    "            x = np.random.randint(0, img_size - w)\n",
    "            y = np.random.randint(0, img_size - h)\n",
    "            bboxes[i_img, i_object] = [x, y, w, h]\n",
    "            cr.move_to(x, y)\n",
    "            cr.line_to(x+w, y)\n",
    "            cr.line_to(x+w, y+h)\n",
    "            cr.line_to(x, y)\n",
    "            cr.close_path()\n",
    "        \n",
    "        # TODO: Introduce some variation to the colors by adding a small random offset to the rgb values.\n",
    "        color = np.random.randint(num_colors)\n",
    "        colors[i_img, i_object] = color\n",
    "        max_offset = 0.3\n",
    "        r_offset, g_offset, b_offset = max_offset * 2. * (np.random.rand(3) - 0.5)\n",
    "        if color == 0:\n",
    "            cr.set_source_rgb(1-max_offset+r_offset, 0+g_offset, 0+b_offset)\n",
    "        elif color == 1:\n",
    "            cr.set_source_rgb(0+r_offset, 1-max_offset+g_offset, 0+b_offset)\n",
    "        elif color == 2:\n",
    "            cr.set_source_rgb(0+r_offset, 0-max_offset+g_offset, 1+b_offset)\n",
    "        cr.fill()\n",
    "        \n",
    "imgs = imgs[..., 2::-1]  # is BGRA, convert to RGB\n",
    "\n",
    "# surface.write_to_png('imgs/{}.png'.format(i_img))\n",
    "imgs.shape, bboxes.shape, shapes.shape, colors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b92dc148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 5\n",
    "plt.imshow(imgs[i], interpolation='none', origin='lower', extent=[0, img_size, 0, img_size])\n",
    "for bbox, shape, color in zip(bboxes[i], shapes[i], colors[i]):\n",
    "    plt.gca().add_patch(matplotlib.patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], ec='k', fc='none'))\n",
    "    plt.annotate(shape_labels[shape], (bbox[0], bbox[1] + bbox[3] + 0.1), color=color_labels[color], clip_on=False)\n",
    "# surface.write_to_png(\"circle.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc5606",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (imgs - 128.) / 255.\n",
    "X.shape, np.mean(X), np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf462112",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colors_onehot = np.zeros((num_imgs, num_objects, num_colors))\n",
    "for i_img in range(num_imgs):\n",
    "    for i_object in range(num_objects):\n",
    "        colors_onehot[i_img, i_object, colors[i_img, i_object]] = 1\n",
    "\n",
    "shapes_onehot = np.zeros((num_imgs, num_objects, num_shapes))\n",
    "for i_img in range(num_imgs):\n",
    "    for i_object in range(num_objects):\n",
    "        shapes_onehot[i_img, i_object, shapes[i_img, i_object]] = 1\n",
    "        \n",
    "y = np.concatenate([bboxes / img_size, shapes_onehot, colors_onehot], axis=-1).reshape(num_imgs, -1)\n",
    "y.shape, np.all(np.argmax(colors_onehot, axis=-1) == colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc856a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = int(0.8 * num_imgs)\n",
    "train_X = X[:i]\n",
    "test_X = X[i:]\n",
    "train_y = y[:i]\n",
    "test_y = y[i:]\n",
    "test_imgs = imgs[i:]\n",
    "test_bboxes = bboxes[i:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae74ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Activation,Conv2D,MaxPooling2D,Flatten\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9236db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28866f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.add(layers.Conv2D(32, (6, 6), activation='relu', input_shape=X.shape[1:]))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8642dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eeada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(layers.Dense(256, activation='softmax'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(layers.Dense(y.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65934fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adadelta',\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ddc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_X, train_y, validation_data=(test_X, test_y), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "\n",
    "# Activate GPU for this, otherwise the convnet will take forever to train with Theano.\n",
    "\n",
    "# TODO: Make one run with very deep network (~10 layers).\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "\n",
    "# TODO: Maybe remove pooling bc it takes away the spatial information.\n",
    "\n",
    "model = Sequential([\n",
    "        Convolution2D(32, 6, 6, input_shape=X.shape[1:], data_format=\"channels_last\", activation='relu'), \n",
    "  #      MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Convolution2D(64, filter_size, filter_size, data_format=\"channels_last\", activation='relu'), \n",
    "      #  MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Convolution2D(128, filter_size, filter_size, data_format=\"channels_last\", activation='relu'), \n",
    "#          MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Convolution2D(128, filter_size, filter_size, data_format=\"channels_last\", activation='relu'), \n",
    " #       MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Flatten(), \n",
    "        Dropout(0.4), \n",
    "        Dense(256, activation='relu'), \n",
    "        Dropout(0.4), \n",
    "        Dense(y.shape[-1])\n",
    "    ])\n",
    "\n",
    "model.compile('adadelta', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce703d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(32,32,3)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4556c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f9067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip bboxes during training.\n",
    "# Note: The validation loss is always quite big here because we don't flip the bounding boxes for the validation data. \n",
    "def IOU(bbox1, bbox2):\n",
    "    '''Calculate overlap between two bounding boxes [x, y, w, h] as the area of intersection over the area of unity'''\n",
    "    x1, y1, w1, h1 = bbox1[0], bbox1[1], bbox1[2], bbox1[3]  # TODO: Check if its more performant if tensor elements are accessed directly below.\n",
    "    x2, y2, w2, h2 = bbox2[0], bbox2[1], bbox2[2], bbox2[3]\n",
    "\n",
    "    w_I = min(x1 + w1, x2 + w2) - max(x1, x2)\n",
    "    h_I = min(y1 + h1, y2 + h2) - max(y1, y2)\n",
    "    if w_I <= 0 or h_I <= 0:  # no overlap\n",
    "        return 0\n",
    "    I = w_I * h_I\n",
    "\n",
    "    U = w1 * h1 + w2 * h2 - I\n",
    "\n",
    "    return I / U\n",
    "\n",
    "def dist(bbox1, bbox2):\n",
    "    return np.sqrt(np.sum(np.square(bbox1[:2] - bbox2[:2])))\n",
    "\n",
    "num_epochs_flipping = 50\n",
    "num_epochs_no_flipping = 0  # has no significant effect\n",
    "\n",
    "flipped_train_y = np.array(train_y)\n",
    "flipped = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "ious_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "dists_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "mses_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "acc_shapes_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "acc_colors_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "\n",
    "flipped_test_y = np.array(test_y)\n",
    "flipped_test = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "ious_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "dists_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "mses_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "acc_shapes_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "acc_colors_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "\n",
    "# TODO: Calculate ious directly for all samples (using slices of the array pred_y for x, y, w, h).\n",
    "for epoch in range(num_epochs_flipping):\n",
    "    print('Epoch', epoch)\n",
    "    model.fit(train_X, flipped_train_y, validation_data=(test_X, test_y), verbose=2)\n",
    "    pred_y = model.predict(train_X)\n",
    "\n",
    "    for sample, (pred, exp) in enumerate(zip(pred_y, flipped_train_y)):\n",
    "        \n",
    "        # TODO: Make this simpler.\n",
    "        pred = pred.reshape(num_objects, -1)\n",
    "        exp = exp.reshape(num_objects, -1)\n",
    "        \n",
    "        pred_bboxes = pred[:, :4]\n",
    "        exp_bboxes = exp[:, :4]\n",
    "        \n",
    "        ious = np.zeros((num_objects, num_objects))\n",
    "        dists = np.zeros((num_objects, num_objects))\n",
    "        mses = np.zeros((num_objects, num_objects))\n",
    "        for i, exp_bbox in enumerate(exp_bboxes):\n",
    "            for j, pred_bbox in enumerate(pred_bboxes):\n",
    "                ious[i, j] = IOU(exp_bbox, pred_bbox)\n",
    "                dists[i, j] = dist(exp_bbox, pred_bbox)\n",
    "                mses[i, j] = np.mean(np.square(exp_bbox - pred_bbox))\n",
    "                \n",
    "        new_order = np.zeros(num_objects, dtype=int)\n",
    "        \n",
    "        for i in range(num_objects):\n",
    "            # Find pred and exp bbox with maximum iou and assign them to each other (i.e. switch the positions of the exp bboxes in y).\n",
    "            ind_exp_bbox, ind_pred_bbox = np.unravel_index(ious.argmax(), ious.shape)\n",
    "            ious_epoch[sample, epoch] += ious[ind_exp_bbox, ind_pred_bbox]\n",
    "            dists_epoch[sample, epoch] += dists[ind_exp_bbox, ind_pred_bbox]\n",
    "            mses_epoch[sample, epoch] += mses[ind_exp_bbox, ind_pred_bbox]\n",
    "            ious[ind_exp_bbox] = -1  # set iou of assigned bboxes to -1, so they don't get assigned again\n",
    "            ious[:, ind_pred_bbox] = -1\n",
    "            new_order[ind_pred_bbox] = ind_exp_bbox\n",
    "        \n",
    "        flipped_train_y[sample] = exp[new_order].flatten()\n",
    "        \n",
    "        flipped[sample, epoch] = 1. - np.mean(new_order == np.arange(num_objects, dtype=int))#np.array_equal(new_order, np.arange(num_objects, dtype=int))  # TODO: Change this to reflect the number of flips.\n",
    "        ious_epoch[sample, epoch] /= num_objects\n",
    "        dists_epoch[sample, epoch] /= num_objects\n",
    "        mses_epoch[sample, epoch] /= num_objects\n",
    "        \n",
    "        acc_shapes_epoch[sample, epoch] = np.mean(np.argmax(pred[:, 4:4+num_shapes], axis=-1) == np.argmax(exp[:, 4:4+num_shapes], axis=-1))\n",
    "        acc_colors_epoch[sample, epoch] = np.mean(np.argmax(pred[:, 4+num_shapes:4+num_shapes+num_colors], axis=-1) == np.argmax(exp[:, 4+num_shapes:4+num_shapes+num_colors], axis=-1))\n",
    "\n",
    "    \n",
    "    # Calculate metrics on test data. \n",
    "    pred_test_y = model.predict(test_X)\n",
    "    # TODO: Make this simpler.\n",
    "    for sample, (pred, exp) in enumerate(zip(pred_test_y, flipped_test_y)):\n",
    "        \n",
    "        # TODO: Make this simpler.\n",
    "        pred = pred.reshape(num_objects, -1)\n",
    "        exp = exp.reshape(num_objects, -1)\n",
    "        \n",
    "        pred_bboxes = pred[:, :4]\n",
    "        exp_bboxes = exp[:, :4]\n",
    "        \n",
    "        ious = np.zeros((num_objects, num_objects))\n",
    "        dists = np.zeros((num_objects, num_objects))\n",
    "        mses = np.zeros((num_objects, num_objects))\n",
    "        for i, exp_bbox in enumerate(exp_bboxes):\n",
    "            for j, pred_bbox in enumerate(pred_bboxes):\n",
    "                ious[i, j] = IOU(exp_bbox, pred_bbox)\n",
    "                dists[i, j] = dist(exp_bbox, pred_bbox)\n",
    "                mses[i, j] = np.mean(np.square(exp_bbox - pred_bbox))\n",
    "                \n",
    "        new_order = np.zeros(num_objects, dtype=int)\n",
    "        \n",
    "        for i in range(num_objects):\n",
    "            # Find pred and exp bbox with maximum iou and assign them to each other (i.e. switch the positions of the exp bboxes in y).\n",
    "            ind_exp_bbox, ind_pred_bbox = np.unravel_index(mses.argmin(), mses.shape)\n",
    "            ious_test_epoch[sample, epoch] += ious[ind_exp_bbox, ind_pred_bbox]\n",
    "            dists_test_epoch[sample, epoch] += dists[ind_exp_bbox, ind_pred_bbox]\n",
    "            mses_test_epoch[sample, epoch] += mses[ind_exp_bbox, ind_pred_bbox]\n",
    "            mses[ind_exp_bbox] = 1000000#-1  # set iou of assigned bboxes to -1, so they don't get assigned again\n",
    "            mses[:, ind_pred_bbox] = 10000000#-1\n",
    "            new_order[ind_pred_bbox] = ind_exp_bbox\n",
    "        \n",
    "        flipped_test_y[sample] = exp[new_order].flatten()\n",
    "        \n",
    "        flipped_test[sample, epoch] = 1. - np.mean(new_order == np.arange(num_objects, dtype=int))#np.array_equal(new_order, np.arange(num_objects, dtype=int))  # TODO: Change this to reflect the number of flips.\n",
    "        ious_test_epoch[sample, epoch] /= num_objects\n",
    "        dists_test_epoch[sample, epoch] /= num_objects\n",
    "        mses_test_epoch[sample, epoch] /= num_objects\n",
    "        \n",
    "        acc_shapes_test_epoch[sample, epoch] = np.mean(np.argmax(pred[:, 4:4+num_shapes], axis=-1) == np.argmax(exp[:, 4:4+num_shapes], axis=-1))\n",
    "        acc_colors_test_epoch[sample, epoch] = np.mean(np.argmax(pred[:, 4+num_shapes:4+num_shapes+num_colors], axis=-1) == np.argmax(exp[:, 4+num_shapes:4+num_shapes+num_colors], axis=-1))\n",
    "       \n",
    "            \n",
    "    print('Flipped {} % of all elements'.format(np.mean(flipped[:, epoch]) * 100.))\n",
    "    print('Mean IOU: {}'.format(np.mean(ious_epoch[:, epoch])))\n",
    "    print('Mean dist: {}'.format(np.mean(dists_epoch[:, epoch])))\n",
    "    print('Mean mse: {}'.format(np.mean(mses_epoch[:, epoch])))\n",
    "    print('Accuracy shapes: {}'.format(np.mean(acc_shapes_epoch[:, epoch])))\n",
    "    print('Accuracy colors: {}'.format(np.mean(acc_colors_epoch[:, epoch])))\n",
    "    \n",
    "    print('--------------- TEST ----------------') \n",
    "    print('Flipped {} % of all elements'.format(np.mean(flipped_test[:, epoch]) * 100.))\n",
    "    print('Mean IOU: {}'.format(np.mean(ious_test_epoch[:, epoch])))\n",
    "    print('Mean dist: {}'.format(np.mean(dists_test_epoch[:, epoch])))\n",
    "    print('Mean mse: {}'.format(np.mean(mses_test_epoch[:, epoch])))\n",
    "    print('Accuracy shapes: {}'.format(np.mean(acc_shapes_test_epoch[:, epoch])))\n",
    "    print('Accuracy colors: {}'.format(np.mean(acc_colors_test_epoch[:, epoch])))\n",
    "    #print\n",
    "    \n",
    "# print '------------------------------------'\n",
    "# print 'Training now without flipping bboxes'\n",
    "# print '------------------------------------'\n",
    "    \n",
    "# for epoch in range(num_epochs_flipping, num_epochs_flipping + num_epochs_no_flipping):\n",
    "#     print 'Epoch', epoch\n",
    "#     model.fit(train_X, flipped_train_y, nb_epoch=1, validation_data=(test_X, test_y), verbose=2)\n",
    "#     pred_y = model.predict(train_X)\n",
    "\n",
    "#     # Calculate iou/dist, but don't flip.\n",
    "#     for sample, (pred_bboxes, exp_bboxes) in enumerate(zip(pred_y, flipped_train_y)):\n",
    "        \n",
    "#         pred_bboxes = pred_bboxes.reshape(num_objects, -1)\n",
    "#         exp_bboxes = exp_bboxes.reshape(num_objects, -1)        \n",
    "        \n",
    "#         for exp_bbox, pred_bbox in zip(exp_bboxes, pred_bboxes):\n",
    "#             ious_epoch[sample, epoch] += IOU(exp_bbox, pred_bbox)\n",
    "#             dists_epoch[sample, epoch] += dist(exp_bbox, pred_bbox)\n",
    "#             mses_epoch[sample, epoch] += np.mean(np.square(exp_bbox - pred_bbox))\n",
    "            \n",
    "#         ious_epoch[sample, epoch] /= num_objects\n",
    "#         dists_epoch[sample, epoch] /= num_objects \n",
    "#         mses_epoch[sample, epoch] /= num_objects \n",
    "            \n",
    "# #     print 'Flipped {} % of all elements'.format(np.mean(flipped[:, epoch]) * 100.)\n",
    "#     print 'Mean IOU: {}'.format(np.mean(ious_epoch[:, epoch]))\n",
    "#     print 'Mean dist: {}'.format(np.mean(dists_epoch[:, epoch]))\n",
    "#     print 'Mean mse: {}'.format(np.mean(mses_epoch[:, epoch]))\n",
    "#     print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aece14e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
