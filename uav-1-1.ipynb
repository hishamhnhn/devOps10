{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43cbdeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12e26fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 32, 32, 3), (500, 2, 4), (500, 2), (500, 2))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cairo\n",
    "num_imgs = 500\n",
    "\n",
    "img_size = 32\n",
    "min_object_size = 4\n",
    "max_object_size = 16\n",
    "num_objects = 2\n",
    "\n",
    "bboxes = np.zeros((num_imgs, num_objects, 4))\n",
    "imgs = np.zeros((num_imgs, img_size, img_size, 4), dtype=np.uint8)  # format: BGRA\n",
    "shapes = np.zeros((num_imgs, num_objects), dtype=int)\n",
    "num_shapes = 3\n",
    "shape_labels = ['rectangle', 'circle', 'triangle']\n",
    "colors = np.zeros((num_imgs, num_objects), dtype=int)\n",
    "num_colors = 3\n",
    "color_labels = ['r', 'g', 'b']\n",
    "\n",
    "for i_img in range(num_imgs):\n",
    "    surface = cairo.ImageSurface.create_for_data(imgs[i_img], cairo.FORMAT_ARGB32, img_size, img_size)\n",
    "    cr = cairo.Context(surface)\n",
    "\n",
    "    # Fill background white.\n",
    "    cr.set_source_rgb(1, 1, 1)\n",
    "    cr.paint()\n",
    "    \n",
    "    # TODO: Try no overlap here.\n",
    "    # Draw random shapes.\n",
    "    for i_object in range(num_objects):\n",
    "        shape = np.random.randint(num_shapes)\n",
    "        shapes[i_img, i_object] = shape\n",
    "        if shape == 0:  # rectangle\n",
    "            w, h = np.random.randint(min_object_size, max_object_size, size=2)\n",
    "            x = np.random.randint(0, img_size - w)\n",
    "            y = np.random.randint(0, img_size - h)\n",
    "            bboxes[i_img, i_object] = [x, y, w, h]\n",
    "            cr.rectangle(x, y, w, h)          \n",
    "        elif shape == 1:  # circle   \n",
    "            r = 0.5 * np.random.randint(min_object_size, max_object_size)\n",
    "            x = np.random.randint(r, img_size - r)\n",
    "            y = np.random.randint(r, img_size - r)\n",
    "            bboxes[i_img, i_object] = [x - r, y - r, 2 * r, 2 * r]\n",
    "            cr.arc(x, y, r, 0, 2*np.pi)\n",
    "        elif shape == 2:  # triangle\n",
    "            w, h = np.random.randint(min_object_size, max_object_size, size=2)\n",
    "            x = np.random.randint(0, img_size - w)\n",
    "            y = np.random.randint(0, img_size - h)\n",
    "            bboxes[i_img, i_object] = [x, y, w, h]\n",
    "            cr.move_to(x, y)\n",
    "            cr.line_to(x+w, y)\n",
    "            cr.line_to(x+w, y+h)\n",
    "            cr.line_to(x, y)\n",
    "            cr.close_path()\n",
    "        \n",
    "        # TODO: Introduce some variation to the colors by adding a small random offset to the rgb values.\n",
    "        color = np.random.randint(num_colors)\n",
    "        colors[i_img, i_object] = color\n",
    "        max_offset = 0.3\n",
    "        r_offset, g_offset, b_offset = max_offset * 2. * (np.random.rand(3) - 0.5)\n",
    "        if color == 0:\n",
    "            cr.set_source_rgb(1-max_offset+r_offset, 0+g_offset, 0+b_offset)\n",
    "        elif color == 1:\n",
    "            cr.set_source_rgb(0+r_offset, 1-max_offset+g_offset, 0+b_offset)\n",
    "        elif color == 2:\n",
    "            cr.set_source_rgb(0+r_offset, 0-max_offset+g_offset, 1+b_offset)\n",
    "        cr.fill()\n",
    "        \n",
    "imgs = imgs[..., 2::-1]  # is BGRA, convert to RGB\n",
    "\n",
    "# surface.write_to_png('imgs/{}.png'.format(i_img))\n",
    "imgs.shape, bboxes.shape, shapes.shape, colors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b92dc148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 5\n",
    "plt.imshow(imgs[i], interpolation='none', origin='lower', extent=[0, img_size, 0, img_size])\n",
    "for bbox, shape, color in zip(bboxes[i], shapes[i], colors[i]):\n",
    "    plt.gca().add_patch(matplotlib.patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], ec='k', fc='none'))\n",
    "    plt.annotate(shape_labels[shape], (bbox[0], bbox[1] + bbox[3] + 0.1), color=color_labels[color], clip_on=False)\n",
    "# surface.write_to_png(\"circle.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc5606",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (imgs - 128.) / 255.\n",
    "X.shape, np.mean(X), np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf462112",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colors_onehot = np.zeros((num_imgs, num_objects, num_colors))\n",
    "for i_img in range(num_imgs):\n",
    "    for i_object in range(num_objects):\n",
    "        colors_onehot[i_img, i_object, colors[i_img, i_object]] = 1\n",
    "\n",
    "shapes_onehot = np.zeros((num_imgs, num_objects, num_shapes))\n",
    "for i_img in range(num_imgs):\n",
    "    for i_object in range(num_objects):\n",
    "        shapes_onehot[i_img, i_object, shapes[i_img, i_object]] = 1\n",
    "        \n",
    "y = np.concatenate([bboxes / img_size, shapes_onehot, colors_onehot], axis=-1).reshape(num_imgs, -1)\n",
    "y.shape, np.all(np.argmax(colors_onehot, axis=-1) == colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc856a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = int(0.8 * num_imgs)\n",
    "train_X = X[:i]\n",
    "test_X = X[i:]\n",
    "train_y = y[:i]\n",
    "test_y = y[i:]\n",
    "test_imgs = imgs[i:]\n",
    "test_bboxes = bboxes[i:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae74ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Activation,Conv2D,MaxPooling2D,Flatten\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9236db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28866f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.add(layers.Conv2D(32, (6, 6), activation='relu', input_shape=X.shape[1:]))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8642dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eeada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(layers.Dense(256, activation='softmax'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(layers.Dense(y.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65934fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adadelta',\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ddc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_X, train_y, validation_data=(test_X, test_y), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "\n",
    "# Activate GPU for this, otherwise the convnet will take forever to train with Theano.\n",
    "\n",
    "# TODO: Make one run with very deep network (~10 layers).\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "\n",
    "# TODO: Maybe remove pooling bc it takes away the spatial information.\n",
    "\n",
    "model = Sequential([\n",
    "        Convolution2D(32, 6, 6, input_shape=X.shape[1:], data_format=\"channels_last\", activation='relu'), \n",
    "  #      MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Convolution2D(64, filter_size, filter_size, data_format=\"channels_last\", activation='relu'), \n",
    "      #  MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Convolution2D(128, filter_size, filter_size, data_format=\"channels_last\", activation='relu'), \n",
    "#          MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Convolution2D(128, filter_size, filter_size, data_format=\"channels_last\", activation='relu'), \n",
    " #       MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Flatten(), \n",
    "        Dropout(0.4), \n",
    "        Dense(256, activation='relu'), \n",
    "        Dropout(0.4), \n",
    "        Dense(y.shape[-1])\n",
    "    ])\n",
    "\n",
    "model.compile('adadelta', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce703d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(32,32,3)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4556c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f9067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip bboxes during training.\n",
    "# Note: The validation loss is always quite big here because we don't flip the bounding boxes for the validation data. \n",
    "def IOU(bbox1, bbox2):\n",
    "    '''Calculate overlap between two bounding boxes [x, y, w, h] as the area of intersection over the area of unity'''\n",
    "    x1, y1, w1, h1 = bbox1[0], bbox1[1], bbox1[2], bbox1[3]  # TODO: Check if its more performant if tensor elements are accessed directly below.\n",
    "    x2, y2, w2, h2 = bbox2[0], bbox2[1], bbox2[2], bbox2[3]\n",
    "\n",
    "    w_I = min(x1 + w1, x2 + w2) - max(x1, x2)\n",
    "    h_I = min(y1 + h1, y2 + h2) - max(y1, y2)\n",
    "    if w_I <= 0 or h_I <= 0:  # no overlap\n",
    "        return 0\n",
    "    I = w_I * h_I\n",
    "\n",
    "    U = w1 * h1 + w2 * h2 - I\n",
    "\n",
    "    return I / U\n",
    "\n",
    "def dist(bbox1, bbox2):\n",
    "    return np.sqrt(np.sum(np.square(bbox1[:2] - bbox2[:2])))\n",
    "\n",
    "num_epochs_flipping = 50\n",
    "num_epochs_no_flipping = 0  # has no significant effect\n",
    "\n",
    "flipped_train_y = np.array(train_y)\n",
    "flipped = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "ious_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "dists_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "mses_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "acc_shapes_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "acc_colors_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "\n",
    "flipped_test_y = np.array(test_y)\n",
    "flipped_test = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "ious_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "dists_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "mses_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "acc_shapes_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "acc_colors_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
    "\n",
    "# TODO: Calculate ious directly for all samples (using slices of the array pred_y for x, y, w, h).\n",
    "for epoch in range(num_epochs_flipping):\n",
    "    print('Epoch', epoch)\n",
    "    model.fit(train_X, flipped_train_y, validation_data=(test_X, test_y), verbose=2)\n",
    "    pred_y = model.predict(train_X)\n",
    "\n",
    "    for sample, (pred, exp) in enumerate(zip(pred_y, flipped_train_y)):\n",
    "        \n",
    "        # TODO: Make this simpler.\n",
    "        pred = pred.reshape(num_objects, -1)\n",
    "        exp = exp.reshape(num_objects, -1)\n",
    "        \n",
    "        pred_bboxes = pred[:, :4]\n",
    "        exp_bboxes = exp[:, :4]\n",
    "        \n",
    "        ious = np.zeros((num_objects, num_objects))\n",
    "        dists = np.zeros((num_objects, num_objects))\n",
    "        mses = np.zeros((num_objects, num_objects))\n",
    "        for i, exp_bbox in enumerate(exp_bboxes):\n",
    "            for j, pred_bbox in enumerate(pred_bboxes):\n",
    "                ious[i, j] = IOU(exp_bbox, pred_bbox)\n",
    "                dists[i, j] = dist(exp_bbox, pred_bbox)\n",
    "                mses[i, j] = np.mean(np.square(exp_bbox - pred_bbox))\n",
    "                \n",
    "        new_order = np.zeros(num_objects, dtype=int)\n",
    "        \n",
    "        for i in range(num_objects):\n",
    "            # Find pred and exp bbox with maximum iou and assign them to each other (i.e. switch the positions of the exp bboxes in y).\n",
    "            ind_exp_bbox, ind_pred_bbox = np.unravel_index(ious.argmax(), ious.shape)\n",
    "            ious_epoch[sample, epoch] += ious[ind_exp_bbox, ind_pred_bbox]\n",
    "            dists_epoch[sample, epoch] += dists[ind_exp_bbox, ind_pred_bbox]\n",
    "            mses_epoch[sample, epoch] += mses[ind_exp_bbox, ind_pred_bbox]\n",
    "            ious[ind_exp_bbox] = -1  # set iou of assigned bboxes to -1, so they don't get assigned again\n",
    "            ious[:, ind_pred_bbox] = -1\n",
    "            new_order[ind_pred_bbox] = ind_exp_bbox\n",
    "        \n",
    "        flipped_train_y[sample] = exp[new_order].flatten()\n",
    "        \n",
    "        flipped[sample, epoch] = 1. - np.mean(new_order == np.arange(num_objects, dtype=int))#np.array_equal(new_order, np.arange(num_objects, dtype=int))  # TODO: Change this to reflect the number of flips.\n",
    "        ious_epoch[sample, epoch] /= num_objects\n",
    "        dists_epoch[sample, epoch] /= num_objects\n",
    "        mses_epoch[sample, epoch] /= num_objects\n",
    "        \n",
    "        acc_shapes_epoch[sample, epoch] = np.mean(np.argmax(pred[:, 4:4+num_shapes], axis=-1) == np.argmax(exp[:, 4:4+num_shapes], axis=-1))\n",
    "        acc_colors_epoch[sample, epoch] = np.mean(np.argmax(pred[:, 4+num_shapes:4+num_shapes+num_colors], axis=-1) == np.argmax(exp[:, 4+num_shapes:4+num_shapes+num_colors], axis=-1))\n",
    "\n",
    "    \n",
    "    # Calculate metrics on test data. \n",
    "    pred_test_y = model.predict(test_X)\n",
    "    # TODO: Make this simpler.\n",
    "    for sample, (pred, exp) in enumerate(zip(pred_test_y, flipped_test_y)):\n",
    "        \n",
    "        # TODO: Make this simpler.\n",
    "        pred = pred.reshape(num_objects, -1)\n",
    "        exp = exp.reshape(num_objects, -1)\n",
    "        \n",
    "        pred_bboxes = pred[:, :4]\n",
    "        exp_bboxes = exp[:, :4]\n",
    "        \n",
    "        ious = np.zeros((num_objects, num_objects))\n",
    "        dists = np.zeros((num_objects, num_objects))\n",
    "        mses = np.zeros((num_objects, num_objects))\n",
    "        for i, exp_bbox in enumerate(exp_bboxes):\n",
    "            for j, pred_bbox in enumerate(pred_bboxes):\n",
    "                ious[i, j] = IOU(exp_bbox, pred_bbox)\n",
    "                dists[i, j] = dist(exp_bbox, pred_bbox)\n",
    "                mses[i, j] = np.mean(np.square(exp_bbox - pred_bbox))\n",
    "                \n",
    "        new_order = np.zeros(num_objects, dtype=int)\n",
    "        \n",
    "        for i in range(num_objects):\n",
    "            # Find pred and exp bbox with maximum iou and assign them to each other (i.e. switch the positions of the exp bboxes in y).\n",
    "            ind_exp_bbox, ind_pred_bbox = np.unravel_index(mses.argmin(), mses.shape)\n",
    "            ious_test_epoch[sample, epoch] += ious[ind_exp_bbox, ind_pred_bbox]\n",
    "            dists_test_epoch[sample, epoch] += dists[ind_exp_bbox, ind_pred_bbox]\n",
    "            mses_test_epoch[sample, epoch] += mses[ind_exp_bbox, ind_pred_bbox]\n",
    "            mses[ind_exp_bbox] = 1000000#-1  # set iou of assigned bboxes to -1, so they don't get assigned again\n",
    "            mses[:, ind_pred_bbox] = 10000000#-1\n",
    "            new_order[ind_pred_bbox] = ind_exp_bbox\n",
    "        \n",
    "        flipped_test_y[sample] = exp[new_order].flatten()\n",
    "        \n",
    "        flipped_test[sample, epoch] = 1. - np.mean(new_order == np.arange(num_objects, dtype=int))#np.array_equal(new_order, np.arange(num_objects, dtype=int))  # TODO: Change this to reflect the number of flips.\n",
    "        ious_test_epoch[sample, epoch] /= num_objects\n",
    "        dists_test_epoch[sample, epoch] /= num_objects\n",
    "        mses_test_epoch[sample, epoch] /= num_objects\n",
    "        \n",
    "        acc_shapes_test_epoch[sample, epoch] = np.mean(np.argmax(pred[:, 4:4+num_shapes], axis=-1) == np.argmax(exp[:, 4:4+num_shapes], axis=-1))\n",
    "        acc_colors_test_epoch[sample, epoch] = np.mean(np.argmax(pred[:, 4+num_shapes:4+num_shapes+num_colors], axis=-1) == np.argmax(exp[:, 4+num_shapes:4+num_shapes+num_colors], axis=-1))\n",
    "       \n",
    "            \n",
    "    print('Flipped {} % of all elements'.format(np.mean(flipped[:, epoch]) * 100.))\n",
    "    print('Mean IOU: {}'.format(np.mean(ious_epoch[:, epoch])))\n",
    "    print('Mean dist: {}'.format(np.mean(dists_epoch[:, epoch])))\n",
    "    print('Mean mse: {}'.format(np.mean(mses_epoch[:, epoch])))\n",
    "    print('Accuracy shapes: {}'.format(np.mean(acc_shapes_epoch[:, epoch])))\n",
    "    print('Accuracy colors: {}'.format(np.mean(acc_colors_epoch[:, epoch])))\n",
    "    \n",
    "    print('--------------- TEST ----------------') \n",
    "    print('Flipped {} % of all elements'.format(np.mean(flipped_test[:, epoch]) * 100.))\n",
    "    print('Mean IOU: {}'.format(np.mean(ious_test_epoch[:, epoch])))\n",
    "    print('Mean dist: {}'.format(np.mean(dists_test_epoch[:, epoch])))\n",
    "    print('Mean mse: {}'.format(np.mean(mses_test_epoch[:, epoch])))\n",
    "    print('Accuracy shapes: {}'.format(np.mean(acc_shapes_test_epoch[:, epoch])))\n",
    "    print('Accuracy colors: {}'.format(np.mean(acc_colors_test_epoch[:, epoch])))\n",
    "    #print\n",
    "    \n",
    "# print '------------------------------------'\n",
    "# print 'Training now without flipping bboxes'\n",
    "# print '------------------------------------'\n",
    "    \n",
    "# for epoch in range(num_epochs_flipping, num_epochs_flipping + num_epochs_no_flipping):\n",
    "#     print 'Epoch', epoch\n",
    "#     model.fit(train_X, flipped_train_y, nb_epoch=1, validation_data=(test_X, test_y), verbose=2)\n",
    "#     pred_y = model.predict(train_X)\n",
    "\n",
    "#     # Calculate iou/dist, but don't flip.\n",
    "#     for sample, (pred_bboxes, exp_bboxes) in enumerate(zip(pred_y, flipped_train_y)):\n",
    "        \n",
    "#         pred_bboxes = pred_bboxes.reshape(num_objects, -1)\n",
    "#         exp_bboxes = exp_bboxes.reshape(num_objects, -1)        \n",
    "        \n",
    "#         for exp_bbox, pred_bbox in zip(exp_bboxes, pred_bboxes):\n",
    "#             ious_epoch[sample, epoch] += IOU(exp_bbox, pred_bbox)\n",
    "#             dists_epoch[sample, epoch] += dist(exp_bbox, pred_bbox)\n",
    "#             mses_epoch[sample, epoch] += np.mean(np.square(exp_bbox - pred_bbox))\n",
    "            \n",
    "#         ious_epoch[sample, epoch] /= num_objects\n",
    "#         dists_epoch[sample, epoch] /= num_objects \n",
    "#         mses_epoch[sample, epoch] /= num_objects \n",
    "            \n",
    "# #     print 'Flipped {} % of all elements'.format(np.mean(flipped[:, epoch]) * 100.)\n",
    "#     print 'Mean IOU: {}'.format(np.mean(ious_epoch[:, epoch]))\n",
    "#     print 'Mean dist: {}'.format(np.mean(dists_epoch[:, epoch]))\n",
    "#     print 'Mean mse: {}'.format(np.mean(mses_epoch[:, epoch]))\n",
    "#     print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aece14e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
